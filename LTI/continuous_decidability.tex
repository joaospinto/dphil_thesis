\section{Decidable Instances}

\label{continuous-decidability}

Given two matrices $A \in \Reals^{n \times n}$ and $B \in \Reals^{n \times d}$, consider the following differential equation:
\begin{equation}
\label{continuous-lti}
\dot{\myvector{x}}(t) = A \myvector{x}(t) + B \myvector{u}(t) .
\end{equation}
The \emph{continuous point-to-point controllability problem for linear time-invariant (LTI) systems} amounts to deciding whether, given initial and target points $s,t \in \Reals^{n}$, there exists a real $T\geq 0$ and a measurable function $\myvector{u}(t) : [0,T] \rightarrow \Reals^{d}$ such that the unique solution to \cref{continuous-lti} starting at $\myvector{x}(0) = \myvector{s}$ satisfies $\myvector{x}(T) = \myvector{t}$.

We will show that this problem is decidable in polynomial time, by reduction from the Continuous Orbit Problem. The \emph{Continuous Orbit Problem} consists of deciding whether, given initial and target points $\myvector{s}, \myvector{t} \in \Reals^{n}$ and a matrix $A \in \Reals^{n \times n}$, the unique solution $\myvector{x}(t) = \exp(A t) \myvector{s}$ of the differential equation
\begin{equation}
\begin{cases}
\dot{\myvector{x}}(t) = A \myvector{x}(t) \\
\myvector{x}(0) = \myvector{s}
\end{cases}
\end{equation}
ever hits $\myvector{t}$. This problem was shown to be decidable in polynomial time in~\cite{ContinuousSkolem1, ContinuousSkolem2}.

Before proceeding, we prove a few simple definitions and preliminary results.

\begin{lemma}
\label{closed-form-solution}
The solution to \cref{continuous-lti} is given by
\begin{equation*}
\myvector{x}(t) = \exp(At) \left( \myvector{x}(0) + \int_{0}^{t} \exp(-Ay) B \myvector{u}(y) \, dy \right).
\end{equation*}
\end{lemma}

\begin{proof}
Let $\myvector{z}(t) = \exp(-At) \myvector{x}(t)$. Then
\begin{align*}
\dot{\myvector{z}}(t) &= -A \myvector{z}(t) + \exp(-At) \dot{\myvector{x}}(t) \\
&= -A \exp(At) \myvector{x}(t) + \exp(-At) A \myvector{x}(t) + \exp(-At) B \myvector{u}(t) \\
&= \exp(-At) B \myvector{u}(t) \\
\Rightarrow \myvector{x}(t) &= \exp(At) \myvector{z}(t) = \exp(At) \left( \myvector{x}(0) + \int_{0}^{t} \exp(-Ay) B \myvector{u}(y) \, dy \right) .
\end{align*}
\end{proof}

\begin{lemma}
\label{integral-invariance}
Let $\mathcal{V}$ be a vector subspace of $\Reals^{n}$ and $f : \Reals^{+}_{0} \rightarrow \mathcal{V}$ be a measurable function. Then, for any $t \geq 0$, $\int_{0}^{t} f(y) dy \in \mathcal{V}$.
\end{lemma}

\begin{proof}
Let $\myvector{r} \in \mathcal{V}^{\perp}$. Then
\begin{equation*}
\myvector{r}^{T} \int_{0}^{t} f(y) \, dy = \int_{0}^{t} \myvector{r}^{T} f(y) \, dy = \int_{0}^{t} 0 \, dy = 0
\end{equation*}
and therefore $\int_{0}^{t} f(y) dy \in (\mathcal{V}^{\perp})^{\perp} = \mathcal{V}$.
\end{proof}

The matrix
\begin{equation}
C= \begin{pmatrix} B && AB && A^{2} B && \cdots && A^{n-1}B \end{pmatrix}
\end{equation}
is called the controllability matrix for the LTI system defined in \cref{continuous-lti}. We will denote its image by $\Im(C)$.

\begin{lemma}
\label{orthogonality-equivalence}
The following are equivalent:
\begin{enumerate}
\item $\myvector{r} \in \Im(C)^{\perp}$.
\item $\myvector{r}^{T} \exp(-Ay) B$ is identically zero on $[0,\infty)$.
\item There exists $T>0$ for which $\myvector{r}^{T} \exp(-Ay) B$ is identically zero on $[0,T]$.
\end{enumerate}
\end{lemma}

\begin{proof}
We show that $(1) \Rightarrow (2)$ and that $(3) \Rightarrow (1)$. It is trivial that $(2) \Rightarrow (3)$.
By the Cayley-Hamilton Theorem, $\myvector{r} \in \Im(C)^{\perp} \Rightarrow \myvector{r}^{T} A^{k} B = 0$ for any $k \geq 0$. The first implication follows from the power series definition of matrix exponentials. For the second implication, note that if $f(y) \triangleq \myvector{r}^{T} \exp(-Ay) B$ is identically zero on $[0,T]$ then $0 = f^{(k)} (0) = \myvector{r}^{T} (-A)^{k} B$.
\end{proof}

\begin{proposition}
For any $T \geq 0$ and $\myvector{v} \in \Im(C)$, there exists a piecewise constant function $\myvector{u} : [0, T] \rightarrow \Reals^{d}$ such that
\begin{equation}
\label{control-existence}
\int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy = \myvector{v}.
\end{equation}
\end{proposition}

\begin{proof}
Let $\mathcal{H}$ denote the space of piecewise constant functions mapping $[0,T]$ to $\Reals^{d}$, and consider the function $g : \mathcal{H} \rightarrow \mathcal{V}$ defined by
\begin{equation*}
g(\myvector{u}) = \int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy.
\end{equation*}
It is clear from \cref{integral-invariance} and from \cref{orthogonality-equivalence} that $\Im(g) \subseteq \Im(C)$. To show the converse containment, let $\myvector{r} \in \Im(g)^{\perp}$. Then, for all $\myvector{u} : [0,T] \rightarrow \Reals^{d}$,
\begin{equation*}
0 = \myvector{r}^{T} \int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy = \int_{0}^{T} \myvector{r}^{T} \exp(-Ay) B \myvector{u}(y) \, dy
\end{equation*}
and therefore $\myvector{r}^{T} \exp(-Ay) B$ must by identically zero on $[0,T]$, due to the arbitrarity of $\myvector{u}$. Thus, we can conclude from \cref{orthogonality-equivalence} that $\myvector{r} \in \Im(C)^{\perp}$, which implies that $\Im(g)^{\perp} \subseteq \Im(C)^{\perp}$, due to the arbitrarity of $\myvector{r}$, implying that $\Im(g) = \Im(C)$.
\end{proof}

We can finally prove the main result of this section.

\begin{theorem}
The continuous point-to-point controllability problem for LTI systems reduces to the continuous orbit problem in polynomial time.
\end{theorem}

\begin{proof}
Consider the quotient vector space $\Reals^{n} / \Im(C)$. Noting that $\Im(C)$ is invariant under $A$, $A$ induces a well-defined linear operator on $\Reals^{n} / \Im(C)$. We claim that $\myvector{t} + \Im(C)$ is in the orbit of $\myvector{s} + \Im(C)$ by $A$ if and only if we can control \cref{continuous-lti} from $\myvector{s}$ to $\myvector{t}$.

If we can control \cref{continuous-lti} from $\myvector{s}$ to $\myvector{t}$ then, due to \cref{closed-form-solution}, there exists $T>0$ such that
\begin{equation*}
\myvector{t} = \myvector{x}(T) = \exp(A T) \left( \myvector{s} + \int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy \right)
\end{equation*}
for some control function $\myvector{u} : [0,T] \rightarrow \Reals^{d}$, so
\begin{equation*}
\myvector{t} + \Im(C) = \exp(A T) (\myvector{s} + \Im(C)),
\end{equation*}
as
\begin{equation*}
\int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy \in \Im(C)
\end{equation*}
due to \cref{integral-invariance}.

On the other hand, suppose that $\myvector{t} + \Im(C)$ is in the orbit of $\myvector{s} + \Im(C)$ by $A$. Then, there exist $T>0$ and $\myvector{v}_{1}, \myvector{v}_{2} \in \Im(C)$ such that
\begin{equation*}
\myvector{t} + \myvector{v}_{2} = \exp(At) \left( \myvector{s} + \myvector{v}_{1} \right).
\end{equation*}

Due to \cref{control-existence}, there exists a control function $\myvector{u} : [0,T] \rightarrow \Reals^{d}$ such that
\begin{equation*}
\int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy = \myvector{v}_{1} - \exp(-A T) \myvector{v}_{2}
\end{equation*}
and so
\begin{align*}
\myvector{x}(T) &= \exp(A T) \left( \myvector{s} + \int_{0}^{T} \exp(-Ay) B \myvector{u}(y) \, dy \right) \\
&= \exp(A T) \left( \myvector{s} + \myvector{v}_{1} - \exp(-A T) \myvector{v}_{2} \right) \\
&= \exp(A T) \left( \myvector{s} + \myvector{v}_{1} \right) - \myvector{v}_{2} = \myvector{t} .
\end{align*}

\end{proof}
