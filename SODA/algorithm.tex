\section{Algorithm for Universal Termination}
Our goal in this section is to prove the following proposition, which
is restated from \cref{sec:overview}.  We have already shown in
\cref{sec:overview} that the main result of this paper,
\cref{thm:main}, then follows.

\begin{proposition}
Given a homogeneous simple linear loop
\begin{gather*}
\mathsf{P4:}\ \mbox{$\myvector{x}\gets \myvector{u}$ ;
\textit{while} $\myvector{b}^T\myvector{x} \geq 0$ \textit{do} $\myvector{x}\leftarrow A\myvector{x}$,}
\end{gather*}
such that $A$ is non-degenerate, we can compute a
witness set for \textsf{P4} using exponential space if all complex eigenvalues of $A$ are simple and using polynomial space if $A$ has dimension at most $5$.
\label{prop:main2}
\end{proposition}

% In \cref{sec:overview} we showed that the main result of this
% paper, \cref{thm:main}, follows from
% \cref{prop:main}.  In this section our goal is to prove the
% latter result, that is, we give a procedure that computes a witness
% set $W$ given a linear loop of the form
% \begin{gather*}
% \mathsf{P4:}\ \mbox{$\myvector{x}\gets \myvector{u}$ ;
% \textit{while} $\myvector{b}^T\myvector{x} \geq 0$ \textit{do} $\myvector{x} \leftarrow
%  A\myvector{x}$,}
% \end{gather*}
% where $A$ is a $d\times d$ integer matrix and $\myvector{b}$ and
% $\myvector{u}$ are $d$-dimensional integer vectors.  We assume that
% $A$ is non-degenerate and either that all complex eigevalues of $A$
% are simple or that $A$ has dimension at most $5$.  By definition, the
% witness set $W$ is required to be convex and semi-algebraic, and to
% satisfy
% \begin{equation*}
% W\cap\Algebraics^d=\mathit{ENT}\cap\Algebraics^d \, ,
% \end{equation*}
% where $\mathit{ENT}$ is the set of eventually non-terminating initial
% values of \textsf{P4}.  The construction of such a witness set will
% occupy this whole section.

Define the \emph{index} of an eigenvalue of $A$ to be its multiplicity
as a root of the minimal polynomial of $A$. An eigenvalue is said to be \textit{simple} if it has index $1$ and \textit{repeated} otherwise. We can write matrix $A$
in the form $A=P^{-1}JP$ for some invertible matrix $P$ and block
diagonal Jordan matrix $J=\mathit{Diag}(J_1,\ldots,J_N)$, with each
block $J_i$ having the form
\[\begin{pmatrix} \lambda & 1 & 0 & \ldots & 0\\
                     0 & \lambda & 1& \ldots & 0\\
                    \vdots & \vdots & \vdots & \ddots & \vdots\\
                   0 & 0 & 0 & \ddots & 1\\
                   0 & 0 & 0 & \ldots & \lambda
\end{pmatrix} \, ,\]
where $\lambda$ is an eigenvalue of $A$ whose index equals the the dimension of the block.
  The entries of $P$
are all algebraic numbers lying in the
extension field of $\Rationals$ generated by the eigenvalues of $A$.

The $n$-th power of the matrix $J$ has the form
$J^n=\mathit{Diag}(J^n_1,\ldots,J^n_N)$, where each block $J_i^n$ has the form
\[\begin{pmatrix}
\lambda^n & n\lambda^{n-1} & \binom{n}{2}\lambda^{n-2}
& \ldots & \binom{n}{\nu-1}\lambda^{n-\nu+1}\\

0 & \lambda^n & n\lambda_i^{n-1} & \ldots &
\binom{n}{\nu-2}\lambda^{n-\nu+2}\\

\vdots & \vdots & \vdots & \ddots & \vdots\\
                   0 & 0 & 0 & \ddots & n\lambda^{n-1}\\
                   0 & 0 & 0 & \ldots & \lambda^n
                 \end{pmatrix} \, ,\] where $\lambda$ is an eigenvalue of $A$ of index $\nu$, and $\binom{n}{k}=0$ if $n<k$.


                 Let $A$ have eigenvalues $\lambda_1,\ldots,\lambda_l$,
                 with respective indices $\nu_1,\ldots,\nu_l$.
Given $\myvector{u}\in\Reals^d$, from
                 our observations on the form of $J^n$, we can write
\begin{gather}
\myvector{b}^TA^n\myvector{u} =
\sum_{j=1}^l \sum_{k=0}^{\nu_j-1}
\myvector{\alpha}_{j,k}^T\myvector{u}\, n^k\lambda_j^n \, ,
\label{eq:master}
\end{gather}
where the $\myvector{\alpha}_{j,k}$ are vectors of algebraic numbers
that do not depend on $\myvector{u}$, and the equation holds for all
$n\geq d$.

Since the characteristic polynomial of $A$ has integer coefficients,
the eigenvalues of $A$ are all algebraic integers.  Moreover, since
for any positive integer $t>0$ we have that $t\cdot
\myvector{b}^TA^n\myvector{u} \geq 0$ if and only if
$\myvector{b}^TA^n\myvector{u}\geq 0$, by rescaling we can assume that
the vectors $\myvector{\alpha}_{j,k}$ in (\ref{eq:master}) are
comprised of algebraic integers.

Now let us partition the eigenvalues of $A$ into sets $S_1,\ldots,S_m$
by grouping eigenvalues of equal modulus.  Assume that $S_1$ contains
eigenvalues of maximum modulus, $S_2$ eigenvalues of the next greatest
modulus, etc.  Correspondingly we write $\Reals^d$ as a
direct sum of subspaces $\Reals^d = V_1 \oplus \ldots \oplus V_m$,
where each subspace $V_i$ is the sum of (generalised) eigenspaces of
$A$ associated to eigenvalues in $S_i$.  By the assumption that $A$ is
non-degenerate, i.e., that no quotient of two distinct eigenvalues is
a root of unity, $S_i$ cannot have both a positive and a negative real
eigenvalue of the same modulus.  Thus each set $S_i$ contains at most one
real eigenvalue.

\subsection{Eventual Non-Termination on Subspace $V_i$}
We first consider the eventual non-termination of \textsf{P4} on
initial vectors in the subspace $V_i$ for a fixed $i \in
\{1,\ldots,m\}$.  Writing $\mathit{ENT}_i := \mathit{ENT} \cap V_i$,
our goal is to show that $\mathit{ENT}_i$ is semi-algebraic.

Given $\myvector{u} \in V_i$, membership of $\myvector{u}$ in
$\mathit{ENT}_i$ can be characterised in terms of the \emph{ultimate
  positivity} of the sequence $\langle\,
\myvector{b}^TA^n\myvector{u}:n\in\mathbb{N}\,\rangle$.  More
precisely, $\myvector{u} \in \mathit{ENT}_i$ if and only if
$\myvector{b}^TA^n\myvector{u} \geq 0$ for all but finitely many
$n$.  In particular, defining
\[ \mathit{ZERO}:=\{\myvector{u} \in \Reals^d: \forall
n\geq d,\, \myvector{b}^TA^n\myvector{u}=0 \} \, \] and
$\mathit{ZERO}_i:=\mathit{ZERO}\cap V_i$, we have that
$\mathit{ZERO}_i\subseteq \mathit{ENT}_i$.

It is easy to see that $\mathit{ZERO}_i$ is semi-algebraic.  Indeed
the uniqueness part of~\cite[Proposition 2.11]{TUCS05} implies that
$\myvector{b}^TA^n\myvector{u}=0$ for all $n\geq d$ if and only if
each term $n^k\lambda_j^n$ has coefficient zero in the expression
(\ref{eq:master}).  Thus
\[ \mathit{ZERO} = \left\{ \myvector{u}\in \Reals^d :
\bigwedge_{j=1}^{l}\bigwedge_{k=0}^{\nu_j-1}
\myvector{\alpha}_{j,k}^T\myvector{u}= 0 \right\} \, .\] is
semi-algebraic.  Since $V_i$ is a semi-algebraic subset of
$\Reals^d$, being spanned by a subset of the columns of $P$, it
follows that $\mathit{ZERO}_i$ is semi-algebraic.

\begin{proposition}
The set $\mathit{ENT}_i$ is semi-algebraic for each $i\in \{1,\ldots,m\}$.
\label{prop:semi-alg}
\end{proposition}
\begin{proof}
  We consider three (overlapping) cases.  Under the hypotheses of
  \cref{prop:main2} at least one of these cases will apply.

\paragraph{Case I: $A$ has dimension at most $5$.}
Assume that $A$ has dimension at most $5$.  The situations in which
$S_i$ does not contain a positive real eigenvalue, or
all of the complex eigenvalues in $S_i$ are simple, will be handled
under Cases II and III, below.  Otherwise, let $\lambda\in S_i$ be a complex
eigenvalue of index at least $2$.  Since $A$ has dimension at most
$5$, it must be the case that $\lambda$ and its complex conjugate
$\overline{\lambda}$ both have index exactly $2$.  Let $\rho \in S_i$
be the positive real eigenvalue.  Since
$A$ has dimension at most $5$, $\rho$ must be simple.  Thus
$S_i=\{\rho,\lambda,\overline{\lambda}\}$ contains all the eigenvalues
of $A$.

For $\myvector{u}\in V_i$ we can write
\begin{align*}
\myvector{b}^TA^n\myvector{u} =
\big(\myvector{\alpha}_0\rho^n  + (\myvector{\beta}_0+ \myvector{\beta}_1n)\lambda^n
 + \overline{(\myvector{\beta}_0+\myvector{\beta}_1n)
\lambda^n}\big)^T\myvector{u} \, ,
\label{eq:small}
\end{align*}
for all $n\geq d$,
where $\myvector{\alpha}_0$ is a vector of real algebraic numbers,
$\myvector{\beta}_0,\myvector{\beta}_1$ are vectors of complex
algebraic numbers.

If $\myvector{\beta}_1^T\myvector{u}\neq 0$, then as $n$ tends to
infinity the dominant terms on the right-hand side above are constant
multiples of $n\lambda^n$ and $n\overline{\lambda^n}$.  In this case
it follows from~\cite[Lemma 4]{Bra06} that
$\myvector{b}^TA^n\myvector{u}$ changes sign infinitely often as
$n$ grows, and hence $\myvector{u}\not\in\mathit{ENT}_i$.

The argument in case $\myvector{\beta}_1^T\myvector{u}=0$ is a
simple version of the approach in Case III, however we include details
since the reader may find this special case instructive.

Define $f:\mathbb{T}\rightarrow\Reals$ by
\[ f(z)=\myvector{\alpha}_0^T\myvector{u}+
\myvector{\beta}_0^T\myvector{u}z+
\overline{\myvector{\beta}_0^T\myvector{u}z} \, .\]
Then $\myvector{b}^TA^n\myvector{u} = \rho^n f(\lambda^n/\rho^n)$ for all $n\geq d$.

Since $A$ is assumed to be non-degenerate, $\lambda/\rho$ is not a
root of unity.  Thus $\{\lambda^n/\rho^n:n\in\mathbb{N}\}$ is dense in
$\mathbb{T}$.  It follows that $\myvector{u}\in\mathit{ENT}$ if and
only if $f(z)\geq 0$ for all $z\in\mathbb{T}$.  By inspection this
last condition is equivalent to $\myvector{\alpha}_0^T\myvector{u}
\geq 2|\myvector{\beta}_0^T\myvector{u}|$.
We conclude that
\[ \mathit{ENT}_i = \left\{ \myvector{u}\in V_i :
\myvector{\beta}_1^T\myvector{u}=0 \wedge
\myvector{\alpha}_0^T\myvector{u} \geq 2|\myvector{\beta}_0^T\myvector{u}| \right\} \, ,\]
and hence $\mathit{ENT}_i$ is semi-algebraic.

\paragraph{Case II: $S_i$ does not contain a positive real eigenvalue.}
It follows from~\cite[Lemma 4]{Bra06} that if $S_i$ does not contain a
positive real eigenvalue then for $\myvector{u}\in V_i$ the sequence
$\myvector{b}^TA^n\myvector{u}$ is either identically zero for $n\geq
d$ or is infinitely often strictly positive and infinitely often
strictly negative.  Thus in this case
$\mathit{ENT}_i=\mathit{ZERO}_i$.  But we have already shown that
$\mathit{ZERO}_i$ is semi-algebraic.


\paragraph{Case III: all complex eigenvalues in $S_i$ are simple.}
Suppose that all complex eigenvalues in $S_i$ are simple.  If $S_i$
contains no positive real eigenvalue then Case II applies.  Thus we
may assume that $S_i$ comprises a positive real eigenvalue $\rho$ of
index $t$ and simple complex eigenvalues
$\lambda_1,\overline{\lambda_1},\ldots,\lambda_s,\overline{\lambda_s}$.
Given $\myvector{u}\in V_i$ we can write
\begin{eqnarray}
\myvector{b}^TA^n\myvector{u} &=& \myvector{b}^TP^{-1}J^nP\myvector{u}
\notag\\
&=& \left[\sum_{j=0}^{t-1} \myvector{\alpha}_j n^j \rho^n + \sum_{j=1}^s
(\myvector{\beta}_j \lambda_j^n + \overline{\myvector{\beta}_j \lambda^n_j})
\right]^T\myvector{u} \, ,
\label{eq:exp-poly}
\end{eqnarray}
where the $\myvector{\alpha}_j$ and $\myvector{\beta}_j$ are
$d$-dimensional vectors of algebraic numbers, with all coefficients of
each $\myvector{\alpha}_j$ being real.

Since $\rho=|\lambda_1|=\ldots=|\lambda_s|$, if
$\myvector{\alpha}_j^T\myvector{u}\neq 0$ for some strictly
positive index $j$, then, for the largest such index $j$, the term
$n^{j}\rho^n\myvector{\alpha}_{j}^T\myvector{u}$ is
dominating on the right-hand side of (\ref{eq:exp-poly}).  In
particular, if $\myvector{\alpha}_{j}^T\myvector{u}>0$ then the
sequence $\myvector{b}^TA^n\myvector{u}$ is ultimately positive
(hence $\myvector{u}\in \mathit{ENT}_i$), and if
$\myvector{\alpha}_{j}^T\myvector{u}<0$ then
$\myvector{b}^TA^n\myvector{u}$ is not ultimately positive (hence
$\myvector{u}\not\in\mathit{ENT}_i$).  It follows that
\begin{gather}
\left\{ \myvector{u} \in V_i : \bigvee_{j=1}^{t-1}\bigwedge_{k=j+1}^{t-1}
(\myvector{\alpha}_j^T \myvector{u}>0 \wedge
\myvector{\alpha}_k^T \myvector{u}=0) \right\}
\label{eq:ENT1}
\end{gather}
is a subset of $\mathit{ENT}_i$.

The case that $\myvector{\alpha}_j^T\myvector{u}=0$ for all
$j=1,\ldots,t-1$ is more subtle since there is no single dominant term
in (\ref{eq:exp-poly}); this is where we employ the results of
\cref{sec:mult} on multiplicative relations. In this case we
rewrite (\ref{eq:exp-poly}) as
\begin{gather}
\myvector{b}^T A^n \myvector{u} =
 \rho^n f\left(\frac{\lambda^n_1}{\rho^n},\ldots,
               \frac{\lambda^n_s}{\rho^n}\right)^T \myvector{u} \, ,
\label{eq:f-exp}
\end{gather}
where $f:\mathbb{T}^s\rightarrow\Reals^d$ is defined by
\[f(z_1,\ldots,z_s)=\myvector{\alpha}_0 + \sum_{j=1}^s \myvector{\beta}_jz_j + \overline{\myvector{\beta}_jz_j} \, .\]
Defining $\myvector\mu=(\lambda_1/\rho,\ldots,\lambda_s/\rho)$, we furthermore rewrite (\ref{eq:f-exp}) as
\begin{gather}
\myvector{b}^T A^n \myvector{u} =
    \rho^n f(\myvector\mu^n)^T \myvector{u} \, .
\label{eq:f2-exp}
\end{gather}

By \cref{dense}, $\{ \myvector\mu^n : n \in
\mathbb{N} \}$ is a dense subset of the torus $T(\myvector{\mu})$.
Thus the right-hand side of (\ref{eq:f2-exp}) is non-negative for
every $n$ if and only if $f(\myvector{z})^T\myvector{u}\geq 0$ for
all $\myvector{z}\in T(\myvector{\mu})$.  It follows that
\begin{gather} \big \{ \myvector{u}\in V_i :
\forall \myvector{z}\in T(\myvector{\mu}),\,
                              f(\myvector{z})^T\myvector{u}\geq 0
\big\}\, .
\label{eq:ENT2}
\end{gather}
is a subset of $\mathit{ENT}_i$.

In \cref{sec:mult} we observed that the set
$T(\myvector{\mu})$ was (effectively) semi-algebraic.  It follows
that we can express the condition $\forall \myvector{z}\in
T(\myvector{\mu}),\, f(\myvector{z})^T\myvector{u}\geq 0$ in the
first-order theory of the reals.  By the Tarski-Seidenberg theorem
\cite{Tar51} on quantifier elimination, the set of $\myvector{u}\in
\Reals^d$ satisfying this condition is semi-algebraic.  But now
$\mathit{ENT}_i$ is the union of the two semi-algebraic sets
(\ref{eq:ENT1}) and (\ref{eq:ENT2}), and therefore $\mathit{ENT}_i$ is
itself semi-algebraic.
\end{proof}
\subsection{Definition of a Witness Set}
Having shown that $\mathit{ZERO}_i$ and $\mathit{ENT}_i$ are
semi-algebraic sets for $i=1,\ldots,m$, we now define a witness set
$W$ for the loop \textsf{P4}.

Given $\myvector{u} \in \Reals^d$, write $\myvector{u}=
\myvector{u}_1+\ldots+\myvector{u}_m$, with $\myvector{u}_1 \in
V_1,\ldots,\myvector{u}_m\in V_m$.  Say that $\myvector{u}_i$ is
the \emph{dominant component} of $\myvector{u}$ if
$\myvector{u}_i\not\in \mathit{ZERO}_i$ and
$\myvector{u}_j\in\mathit{ZERO}_j$ for all $j<i$.  The intuition is
that if $\myvector{u}_i$ is dominant then the eventual
non-termination of \textsf{P4} on $\myvector{u}$ is determined by
its eventual non-termination on $\myvector{u}_i$.  However, to prove
this we need to assume $\myvector{u}\in (\Algebraics\cap\Reals)^d$.  Formally we
have:

\begin{proposition}
  If $\myvector{u}_i$ is the dominant component of $\myvector{u}
  \in (\Algebraics\cap\Reals)^d$ then $\myvector{u}\in\mathit{ENT}$ if and only
if $\myvector{u}_i \in \mathit{ENT}$.
\label{prop:dominant}
\end{proposition}
\begin{proof}
From the fact that $\myvector{u}_i$ is dominant we have:
\begin{eqnarray}
 \myvector{b}^TA^n\myvector{u}&=&
   \myvector{b}^TA^n(\myvector{u}_1+\cdots+\myvector{u}_m) \notag\\
&=&\myvector{b}^TA^n(\myvector{u}_i+\cdots+\myvector{u}_m)
\label{eq:part}
\end{eqnarray}
for all $n\geq d$.  Moreover, for each $j>i$ it is clear that
  $|\myvector{b}^TA^n\myvector{u}_j| = O(n^d\rho_j^n)$, where
  $\rho_j\geq 0$ is the modulus of the eigenvalues in $S_j$.

  We now consider three cases, mirroring the proof of
  \cref{prop:semi-alg}.

  The first case is that $A$ has dimension at most $5$.  As observed
  in the proof of \cref{prop:semi-alg}, all instances of
  this case that are not already covered by the second and third cases
  are such that $S_i$ contains all the eigenvalues of $A$, and hence
  $\myvector{u}_i=\myvector{u}$.  In this situation the proposition
  holds trivially.

  The second case is that $S_i$ does not contain a positive real
  eigenvalue.  Then it follows from~\cite[Lemma 4]{Bra06} that there
  is a constant $c<0$ such that
  $\myvector{b}^TA^n\myvector{u}_i<c\rho_i^n$ for infinitely many
  $n$.  In this case neither $\myvector{u}_i$ nor $\myvector{u}$
  are elements of $\mathit{ENT}$.

  It remains to consider the case that all complex eigenvalues in
  $S_i$ are simple.  Suppose that the dominant term in the expression
  for $\myvector{b}^TA^n\myvector{u}_i$ has the form $\alpha
  n^k\rho_i^n$ for some real constant $\alpha\neq 0$ and $k>0$.  If
  $\alpha>0$ then both $\myvector{u}$ and $\myvector{u}_i$ are in
  $\mathit{ENT}$ and if $\alpha<0$ then neither $\myvector{u}$ or
  $\myvector{u}_i$ are in $\mathit{ENT}$.

  Otherwise, specialising the expression (\ref{eq:master}) to the case
  at hand, we have that
\begin{gather}
\label{eq:diag}
 \myvector{b}^TA^n\myvector{u}_i = \alpha_0 \rho_i^n+\sum\limits_{j=1}^s\beta_j\lambda_j^n+\overline{\beta_j\lambda_j^n}
\end{gather}
where $\alpha_0$ and the $\beta_j$ are algebraic-integer constants and
$\rho_i,\lambda_1,\overline{\lambda_1},\ldots,\lambda_s,\overline{\lambda_s} \in S_i$.  In this case one can use the
$S$-units theorem of Evertse, van der Poorten, and
Schlickewei~\cite{Evertse84,PS82} to show that for all $\varepsilon>0$ it
is the case that $\myvector{b}^TA^n\myvector{u}_i =\Omega\left(
  \rho_i^n \Lambda^{-n\varepsilon} \right)$,
where $\Lambda$ is an upper bound on the absolute value of eigenvalues of $A$ (see the Appendix for details).

From this lower bound, taking $\varepsilon$ suitably small, it follows
that $|\myvector{b}^TA^n\myvector{u}_j|=o(|\myvector{b}^TA^n
\myvector{u}_i|)$ for all $j>i$ and hence that
$\myvector{u}\in\mathit{ENT}$ if and only if $\myvector{u}_i\in
\mathit{ENT}$.
\end{proof}

Now we define a witness set $W$ for program \textsf{P4} by
\begin{align*}
W :=   \bigcup_{i=1}^m \{\myvector{u}\in \Reals^d: \,
         & \myvector{u}_i \mbox{ is the dominant component of } \myvector{u},\\
         & \myvector{u}_i \in \mathit{ENT} \}
\cup \mathit{ZERO} \, .
\end{align*}

From the fact that $\mathit{ZERO}_i$, $\mathit{ENT}_i$, and $V_i$ are
semi-algebraic for $i=1,\ldots,m$, it is easy to see that $W$ is
semi-algebraic.  It moreover follows from \cref{prop:dominant}
that $W \cap \Algebraics^d = \mathit{ENT} \cap \Algebraics^d$.

To conclude the proof of \cref{prop:main2}, it
remains to observe that the witness set $W$, like the actual set
$\mathit{ENT}$ of eventually non-terminating points, is convex.
\begin{proposition}
The witness set $W$ is convex.
\end{proposition}
\begin{proof}
  Suppose $\myvector y,\myvector z\in W$ and let $\myvector
  x=\lambda\myvector y+(1-\lambda)\myvector z$, where $0 < \lambda
  < 1$. Moreover, write
  $\myvector{x}=\myvector{x}_1+\ldots+\myvector{x}_m$, where
  $\myvector{x}_1\in V_1,\ldots,\myvector{x}_m\in V_m$, and
  likewise for $\myvector{y}$ and $\myvector{z}$.

If $\myvector{y},\myvector{z}\in \mathit{ZERO}$ then
$\myvector{x}\in \mathit{ZERO}$ since the latter is a convex set.

Suppose that $\myvector{y}\in \mathit{ZERO}$ and $\myvector{z}_i \in \mathit{ENT}$ is dominant for $\myvector{z}$ for some index $i\in\{1,\ldots,m\}$.
Then $\myvector{x}_i$ is dominant for $\myvector{x}$, and
$\myvector{x}_i \in \mathit{ENT}$.  Thus $\myvector{x}\in W$.

Otherwise, let $\myvector y_i$ be dominant for $\myvector y$ and
$\myvector z_j$ be dominant for $\myvector z$ for some
$i,j\in\{1,\ldots,m\}$.  Then $\myvector x_k\in \mathit{ZERO}_k$ for
all $k<\min\lbrace i,j\rbrace$ since $\mathit{ZERO}_k$ is convex.
Moreover if $k=\min\lbrace i,j\rbrace$ then $\myvector
y_k,\myvector z_k \in \mathit{ENT}_k$, and hence $\myvector x_k
\in \mathit{ENT}_k$ by convexity of $\mathit{ENT}_k$.  It follows that
$\myvector{x}\in W$.
\end{proof}

This concludes the proof of \cref{prop:main2}.
In the remaining part of this section we show that
$\overline{\mathit{ENT}}=\overline{W}$.

The inclusion $\overline{W}\subseteq \overline{ENT}$ can be shown
using the fact that the set algebraic points in any semi-algebraic set
is dense in that set. (See the Appendix for details).  From
this we have:
\begin{align*}
\overline{W}=\overline{W\cap\Algebraics^d}=\overline{\mathit{ENT}\cap\Algebraics^d} \subseteq \overline{\mathit{ENT}}\cap\overline{\Algebraics^d}=\overline{\mathit{ENT}}
\end{align*}

The reverse inclusion, $\overline{ENT}\subseteq\overline{W}$, can be
shown in similar fashion but this time using the fact that
$\mathit{ENT}\cap\Algebraics^d$ is dense in $\mathit{ENT}$.  Our
remaining goal is this last fact, which is established in
\cref{corl:dense} below.

We have previously shown that a vector of algebraic numbers
$\myvector{u}\in (\Algebraics\cap\Reals)^d$ is eventually
non-terminating if and only if its dominant component
$\myvector{u}_i$ is eventually non-terminating.  We now prove a
partial result of this nature for general vectors $\myvector{u}\in
\Reals^d$.

\begin{proposition}
  Suppose that $\myvector u=\myvector u_1+\cdots+\myvector
  u_m\in \Reals^d$, where $\myvector u_1\in
  V_1,\ldots,\myvector u_m\in V_m$. Then $\myvector
  u\in\mathit{ENT}$ implies that its dominant component $\myvector
  u_i$ is also in \textit{ENT}.
\label{prop:dom2}
\end{proposition}
\begin{proof}
  The only non-trivial case corresponds to the situation in which
  $\myvector b^T A^n \myvector u_i$ is of the form (\ref{eq:diag}).
  Let $f$ and $\myvector \mu$ be as in (\ref{eq:f-exp}), that is, so
  that $\myvector b^T A^n \myvector u_i=\rho_i^n f (\myvector
  \mu^n)^T \myvector u_i$. If $\myvector u_i\not\in\mathit{ENT}$,
  then there exists some constant $c<0$ and some $\myvector z\in T(\myvector \mu)$ such that $f(\myvector z)^T \myvector u_i=c$. Therefore, for any $\varepsilon>0$, $\myvector b^T A^n \myvector u_i<(c+\varepsilon)\rho_i^n$ holds for infinitely many $n$, due to \cref{dense} and to continuity of $f$, and so $\myvector u\not\in\mathit{ENT}$.
\end{proof}

\begin{corollary}
$\mathit{ENT}\cap\Algebraics^d$ is dense in \textit{ENT}.
\label{corl:dense}
\end{corollary}

\begin{proof}
  At several points we will rely on the fact that if
  $X\subseteq\Reals^d$ is semi-algebraic, then the algebraic
  points in $X$ are dense in $X$.  (See Appendix for details.)

  Fix $\myvector u\in\mathit{ENT}$ and let $\varepsilon>0$ be
  given. We will find $\myvector v\in \mathit{ENT}\cap \Algebraics^d$
  such that $||\myvector u-\myvector v||<\varepsilon$.

  The case in which $\myvector u \in \mathit{ZERO}$ is easy since
  $\mathit{ZERO}$ is semi-algebraic and so we can take $\myvector v$
  to be an algebraic point in $\mathit{ZERO}$ that is suitably close
  to $\myvector u$.

  Suppose now that $\myvector u=\myvector u_1+\cdots+\myvector
  u_m$, where $\myvector u_1\in V_1,\ldots,\myvector u_m\in V_m$,
  with $\myvector u_i$ the dominant component of $\myvector u$. By
  \cref{prop:dom2}, $\myvector u\in\mathit{ENT}$ implies
  that $\myvector u_i\in \mathit{ENT}$. Since $\mathit{ENT}\cap V_i$
  is semi-algebraic, we can pick $\myvector v_i\in \mathit{ENT}\cap
  V_i\cap\Algebraics^d$ such that $\| \myvector v_i -\myvector u_i
  \|<\varepsilon/n$. For each $j>i$, we pick some $\myvector v_j\in
  V_j\cap \Algebraics^d$ for which $\| \myvector v_j - \myvector
  u_j\|<\varepsilon/n$.  For each $j<i$ we pick some $v_j \in
  \mathit{ZERO}\cap V_j\cap \Algebraics^d$ for which $\| \myvector
  v_j - \myvector u_j\|<\varepsilon/n$.

  Then, letting $\myvector v=\myvector v_1+\cdots+\myvector v_m
  \in \Algebraics^d$, it follows that $\|\myvector u-\myvector
  v\|<\varepsilon$.  Finally, by \cref{prop:dominant} we
  have $\myvector v\in\mathit{ENT}$ since $\myvector v_i$ is the
  dominant component of $\myvector v$ and $\myvector v_i \in
  \mathit{ENT}$ by construction.
\end{proof}
