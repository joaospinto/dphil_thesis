\section{Algorithm for Universal Termination}
Our goal in this section is to prove the following proposition, which
is restated from \cref{sec:overview}.  We have already shown in
\cref{sec:overview} that the main result of this paper,
\cref{thm:main}, then follows.

\begin{proposition}
Given a homogeneous simple linear loop
\begin{gather*}
\mathsf{P4:}\ \mbox{$\boldsymbol{x}\gets \boldsymbol{u}$ ;
\textit{while} $\boldsymbol{b}^T\boldsymbol{x} \geq 0$ \textit{do} $\boldsymbol{x}\leftarrow A\boldsymbol{x}$,}
\end{gather*}
such that $A$ is non-degenerate, we can compute a
witness set for \textsf{P4} using exponential space if all complex eigenvalues of $A$ are simple and using polynomial space if $A$ has dimension at most $5$.
\label{prop:main2}
\end{proposition}

% In \cref{sec:overview} we showed that the main result of this
% paper, \cref{thm:main}, follows from
% \cref{prop:main}.  In this section our goal is to prove the
% latter result, that is, we give a procedure that computes a witness
% set $W$ given a linear loop of the form
% \begin{gather*}
% \mathsf{P4:}\ \mbox{$\boldsymbol{x}\gets \boldsymbol{u}$ ;
% \textit{while} $\boldsymbol{b}^T\boldsymbol{x} \geq 0$ \textit{do} $\boldsymbol{x} \leftarrow
%  A\boldsymbol{x}$,}
% \end{gather*}
% where $A$ is a $d\times d$ integer matrix and $\boldsymbol{b}$ and
% $\boldsymbol{u}$ are $d$-dimensional integer vectors.  We assume that
% $A$ is non-degenerate and either that all complex eigevalues of $A$
% are simple or that $A$ has dimension at most $5$.  By definition, the
% witness set $W$ is required to be convex and semi-algebraic, and to
% satisfy
% \begin{equation*}
% W\cap\mathbb{A}^d=\mathit{ENT}\cap\mathbb{A}^d \, ,
% \end{equation*}
% where $\mathit{ENT}$ is the set of eventually non-terminating initial
% values of \textsf{P4}.  The construction of such a witness set will
% occupy this whole section.

Define the \emph{index} of an eigenvalue of $A$ to be its multiplicity
as a root of the minimal polynomial of $A$. An eigenvalue is said to be \textit{simple} if it has index $1$ and \textit{repeated} otherwise. We can write matrix $A$
in the form $A=P^{-1}JP$ for some invertible matrix $P$ and block
diagonal Jordan matrix $J=\mathit{Diag}(J_1,\ldots,J_N)$, with each
block $J_i$ having the form
\[\begin{pmatrix} \lambda & 1 & 0 & \ldots & 0\\
                     0 & \lambda & 1& \ldots & 0\\
                    \vdots & \vdots & \vdots & \ddots & \vdots\\
                   0 & 0 & 0 & \ddots & 1\\
                   0 & 0 & 0 & \ldots & \lambda
\end{pmatrix} \, ,\]
where $\lambda$ is an eigenvalue of $A$ whose index equals the the dimension of the block.
  The entries of $P$
are all algebraic numbers lying in the
extension field of $\mathbb{Q}$ generated by the eigenvalues of $A$.

The $n$-th power of the matrix $J$ has the form
$J^n=\mathit{Diag}(J^n_1,\ldots,J^n_N)$, where each block $J_i^n$ has the form
\[\begin{pmatrix}
\lambda^n & n\lambda^{n-1} & \binom{n}{2}\lambda^{n-2}
& \ldots & \binom{n}{\nu-1}\lambda^{n-\nu+1}\\

0 & \lambda^n & n\lambda_i^{n-1} & \ldots &
\binom{n}{\nu-2}\lambda^{n-\nu+2}\\

\vdots & \vdots & \vdots & \ddots & \vdots\\
                   0 & 0 & 0 & \ddots & n\lambda^{n-1}\\
                   0 & 0 & 0 & \ldots & \lambda^n
                 \end{pmatrix} \, ,\] where $\lambda$ is an eigenvalue of $A$ of index $\nu$, and $\binom{n}{k}=0$ if $n<k$.


                 Let $A$ have eigenvalues $\lambda_1,\ldots,\lambda_l$,
                 with respective indices $\nu_1,\ldots,\nu_l$.
Given $\boldsymbol{u}\in\mathbb{R}^d$, from
                 our observations on the form of $J^n$, we can write
\begin{gather}
\boldsymbol{b}^TA^n\boldsymbol{u} =
\sum_{j=1}^l \sum_{k=0}^{\nu_j-1}
\boldsymbol{\alpha}_{j,k}^T\boldsymbol{u}\, n^k\lambda_j^n \, ,
\label{eq:master}
\end{gather}
where the $\boldsymbol{\alpha}_{j,k}$ are vectors of algebraic numbers
that do not depend on $\boldsymbol{u}$, and the equation holds for all
$n\geq d$.

Since the characteristic polynomial of $A$ has integer coefficients,
the eigenvalues of $A$ are all algebraic integers.  Moreover, since
for any positive integer $t>0$ we have that $t\cdot
\boldsymbol{b}^TA^n\boldsymbol{u} \geq 0$ if and only if
$\boldsymbol{b}^TA^n\boldsymbol{u}\geq 0$, by rescaling we can assume that
the vectors $\boldsymbol{\alpha}_{j,k}$ in (\ref{eq:master}) are
comprised of algebraic integers.

Now let us partition the eigenvalues of $A$ into sets $S_1,\ldots,S_m$
by grouping eigenvalues of equal modulus.  Assume that $S_1$ contains
eigenvalues of maximum modulus, $S_2$ eigenvalues of the next greatest
modulus, etc.  Correspondingly we write $\mathbb{R}^d$ as a
direct sum of subspaces $\mathbb{R}^d = V_1 \oplus \ldots \oplus V_m$,
where each subspace $V_i$ is the sum of (generalised) eigenspaces of
$A$ associated to eigenvalues in $S_i$.  By the assumption that $A$ is
non-degenerate, i.e., that no quotient of two distinct eigenvalues is
a root of unity, $S_i$ cannot have both a positive and a negative real
eigenvalue of the same modulus.  Thus each set $S_i$ contains at most one
real eigenvalue.

\subsection{Eventual Non-Termination on Subspace $V_i$}
We first consider the eventual non-termination of \textsf{P4} on
initial vectors in the subspace $V_i$ for a fixed $i \in
\{1,\ldots,m\}$.  Writing $\mathit{ENT}_i := \mathit{ENT} \cap V_i$,
our goal is to show that $\mathit{ENT}_i$ is semi-algebraic.

Given $\boldsymbol{u} \in V_i$, membership of $\boldsymbol{u}$ in
$\mathit{ENT}_i$ can be characterised in terms of the \emph{ultimate
  positivity} of the sequence $\langle\,
\boldsymbol{b}^TA^n\boldsymbol{u}:n\in\mathbb{N}\,\rangle$.  More
precisely, $\boldsymbol{u} \in \mathit{ENT}_i$ if and only if
$\boldsymbol{b}^TA^n\boldsymbol{u} \geq 0$ for all but finitely many
$n$.  In particular, defining
\[ \mathit{ZERO}:=\{\boldsymbol{u} \in \mathbb{R}^d: \forall
n\geq d,\, \boldsymbol{b}^TA^n\boldsymbol{u}=0 \} \, \] and
$\mathit{ZERO}_i:=\mathit{ZERO}\cap V_i$, we have that
$\mathit{ZERO}_i\subseteq \mathit{ENT}_i$.

It is easy to see that $\mathit{ZERO}_i$ is semi-algebraic.  Indeed
the uniqueness part of~\cite[Proposition 2.11]{TUCS05} implies that
$\boldsymbol{b}^TA^n\boldsymbol{u}=0$ for all $n\geq d$ if and only if
each term $n^k\lambda_j^n$ has coefficient zero in the expression
(\ref{eq:master}).  Thus
\[ \mathit{ZERO} = \left\{ \boldsymbol{u}\in \mathbb{R}^d :
\bigwedge_{j=1}^{l}\bigwedge_{k=0}^{\nu_j-1}
\boldsymbol{\alpha}_{j,k}^T\boldsymbol{u}= 0 \right\} \, .\] is
semi-algebraic.  Since $V_i$ is a semi-algebraic subset of
$\mathbb{R}^d$, being spanned by a subset of the columns of $P$, it
follows that $\mathit{ZERO}_i$ is semi-algebraic.

\begin{proposition}
The set $\mathit{ENT}_i$ is semi-algebraic for each $i\in \{1,\ldots,m\}$.
\label{prop:semi-alg}
\end{proposition}
\begin{proof}
  We consider three (overlapping) cases.  Under the hypotheses of
  \cref{prop:main2} at least one of these cases will apply.

\paragraph{Case I: $A$ has dimension at most $5$.}
Assume that $A$ has dimension at most $5$.  The situations in which
$S_i$ does not contain a positive real eigenvalue, or
all of the complex eigenvalues in $S_i$ are simple, will be handled
under Cases II and III, below.  Otherwise, let $\lambda\in S_i$ be a complex
eigenvalue of index at least $2$.  Since $A$ has dimension at most
$5$, it must be the case that $\lambda$ and its complex conjugate
$\overline{\lambda}$ both have index exactly $2$.  Let $\rho \in S_i$
be the positive real eigenvalue.  Since
$A$ has dimension at most $5$, $\rho$ must be simple.  Thus
$S_i=\{\rho,\lambda,\overline{\lambda}\}$ contains all the eigenvalues
of $A$.

For $\boldsymbol{u}\in V_i$ we can write
\begin{align*}
\boldsymbol{b}^TA^n\boldsymbol{u} =
\big(\boldsymbol{\alpha}_0\rho^n  + (\boldsymbol{\beta}_0+ \boldsymbol{\beta}_1n)\lambda^n
 + \overline{(\boldsymbol{\beta}_0+\boldsymbol{\beta}_1n)
\lambda^n}\big)^T\boldsymbol{u} \, ,
\label{eq:small}
\end{align*}
for all $n\geq d$,
where $\boldsymbol{\alpha}_0$ is a vector of real algebraic numbers,
$\boldsymbol{\beta}_0,\boldsymbol{\beta}_1$ are vectors of complex
algebraic numbers.

If $\boldsymbol{\beta}_1^T\boldsymbol{u}\neq 0$, then as $n$ tends to
infinity the dominant terms on the right-hand side above are constant
multiples of $n\lambda^n$ and $n\overline{\lambda^n}$.  In this case
it follows from~\cite[Lemma 4]{Bra06} that
$\boldsymbol{b}^TA^n\boldsymbol{u}$ changes sign infinitely often as
$n$ grows, and hence $\boldsymbol{u}\not\in\mathit{ENT}_i$.

The argument in case $\boldsymbol{\beta}_1^T\boldsymbol{u}=0$ is a
simple version of the approach in Case III, however we include details
since the reader may find this special case instructive.

Define $f:\mathbb{T}\rightarrow\mathbb{R}$ by
\[ f(z)=\boldsymbol{\alpha}_0^T\boldsymbol{u}+
\boldsymbol{\beta}_0^T\boldsymbol{u}z+
\overline{\boldsymbol{\beta}_0^T\boldsymbol{u}z} \, .\]
Then $\boldsymbol{b}^TA^n\boldsymbol{u} = \rho^n f(\lambda^n/\rho^n)$ for all $n\geq d$.

Since $A$ is assumed to be non-degenerate, $\lambda/\rho$ is not a
root of unity.  Thus $\{\lambda^n/\rho^n:n\in\mathbb{N}\}$ is dense in
$\mathbb{T}$.  It follows that $\boldsymbol{u}\in\mathit{ENT}$ if and
only if $f(z)\geq 0$ for all $z\in\mathbb{T}$.  By inspection this
last condition is equivalent to $\boldsymbol{\alpha}_0^T\boldsymbol{u}
\geq 2|\boldsymbol{\beta}_0^T\boldsymbol{u}|$.
We conclude that
\[ \mathit{ENT}_i = \left\{ \boldsymbol{u}\in V_i :
\boldsymbol{\beta}_1^T\boldsymbol{u}=0 \wedge
\boldsymbol{\alpha}_0^T\boldsymbol{u} \geq 2|\boldsymbol{\beta}_0^T\boldsymbol{u}| \right\} \, ,\]
and hence $\mathit{ENT}_i$ is semi-algebraic.

\paragraph{Case II: $S_i$ does not contain a positive real eigenvalue.}
It follows from~\cite[Lemma 4]{Bra06} that if $S_i$ does not contain a
positive real eigenvalue then for $\boldsymbol{u}\in V_i$ the sequence
$\boldsymbol{b}^TA^n\boldsymbol{u}$ is either identically zero for $n\geq
d$ or is infinitely often strictly positive and infinitely often
strictly negative.  Thus in this case
$\mathit{ENT}_i=\mathit{ZERO}_i$.  But we have already shown that
$\mathit{ZERO}_i$ is semi-algebraic.


\paragraph{Case III: all complex eigenvalues in $S_i$ are simple.}
Suppose that all complex eigenvalues in $S_i$ are simple.  If $S_i$
contains no positive real eigenvalue then Case II applies.  Thus we
may assume that $S_i$ comprises a positive real eigenvalue $\rho$ of
index $t$ and simple complex eigenvalues
$\lambda_1,\overline{\lambda_1},\ldots,\lambda_s,\overline{\lambda_s}$.
Given $\boldsymbol{u}\in V_i$ we can write
\begin{eqnarray}
\boldsymbol{b}^TA^n\boldsymbol{u} &=& \boldsymbol{b}^TP^{-1}J^nP\boldsymbol{u}
\notag\\
&=& \left[\sum_{j=0}^{t-1} \boldsymbol{\alpha}_j n^j \rho^n + \sum_{j=1}^s
(\boldsymbol{\beta}_j \lambda_j^n + \overline{\boldsymbol{\beta}_j \lambda^n_j})
\right]^T\boldsymbol{u} \, ,
\label{eq:exp-poly}
\end{eqnarray}
where the $\boldsymbol{\alpha}_j$ and $\boldsymbol{\beta}_j$ are
$d$-dimensional vectors of algebraic numbers, with all coefficients of
each $\boldsymbol{\alpha}_j$ being real.

Since $\rho=|\lambda_1|=\ldots=|\lambda_s|$, if
$\boldsymbol{\alpha}_j^T\boldsymbol{u}\neq 0$ for some strictly
positive index $j$, then, for the largest such index $j$, the term
$n^{j}\rho^n\boldsymbol{\alpha}_{j}^T\boldsymbol{u}$ is
dominating on the right-hand side of (\ref{eq:exp-poly}).  In
particular, if $\boldsymbol{\alpha}_{j}^T\boldsymbol{u}>0$ then the
sequence $\boldsymbol{b}^TA^n\boldsymbol{u}$ is ultimately positive
(hence $\boldsymbol{u}\in \mathit{ENT}_i$), and if
$\boldsymbol{\alpha}_{j}^T\boldsymbol{u}<0$ then
$\boldsymbol{b}^TA^n\boldsymbol{u}$ is not ultimately positive (hence
$\boldsymbol{u}\not\in\mathit{ENT}_i$).  It follows that
\begin{gather}
\left\{ \boldsymbol{u} \in V_i : \bigvee_{j=1}^{t-1}\bigwedge_{k=j+1}^{t-1}
(\boldsymbol{\alpha}_j^T \boldsymbol{u}>0 \wedge
\boldsymbol{\alpha}_k^T \boldsymbol{u}=0) \right\}
\label{eq:ENT1}
\end{gather}
is a subset of $\mathit{ENT}_i$.

The case that $\boldsymbol{\alpha}_j^T\boldsymbol{u}=0$ for all
$j=1,\ldots,t-1$ is more subtle since there is no single dominant term
in (\ref{eq:exp-poly}); this is where we employ the results of
\cref{sec:mult} on multiplicative relations. In this case we
rewrite (\ref{eq:exp-poly}) as
\begin{gather}
\boldsymbol{b}^T A^n \boldsymbol{u} =
 \rho^n f\left(\frac{\lambda^n_1}{\rho^n},\ldots,
               \frac{\lambda^n_s}{\rho^n}\right)^T \boldsymbol{u} \, ,
\label{eq:f-exp}
\end{gather}
where $f:\mathbb{T}^s\rightarrow\mathbb{R}^d$ is defined by
\[f(z_1,\ldots,z_s)=\boldsymbol{\alpha}_0 + \sum_{j=1}^s \boldsymbol{\beta}_jz_j + \overline{\boldsymbol{\beta}_jz_j} \, .\]
Defining $\boldsymbol\mu=(\lambda_1/\rho,\ldots,\lambda_s/\rho)$, we furthermore rewrite (\ref{eq:f-exp}) as
\begin{gather}
\boldsymbol{b}^T A^n \boldsymbol{u} =
    \rho^n f(\boldsymbol\mu^n)^T \boldsymbol{u} \, .
\label{eq:f2-exp}
\end{gather}

By \cref{dense}, $\{ \boldsymbol\mu^n : n \in
\mathbb{N} \}$ is a dense subset of the torus $T(\boldsymbol{\mu})$.
Thus the right-hand side of (\ref{eq:f2-exp}) is non-negative for
every $n$ if and only if $f(\boldsymbol{z})^T\boldsymbol{u}\geq 0$ for
all $\boldsymbol{z}\in T(\boldsymbol{\mu})$.  It follows that
\begin{gather} \big \{ \boldsymbol{u}\in V_i :
\forall \boldsymbol{z}\in T(\boldsymbol{\mu}),\,
                              f(\boldsymbol{z})^T\boldsymbol{u}\geq 0
\big\}\, .
\label{eq:ENT2}
\end{gather}
is a subset of $\mathit{ENT}_i$.

In \cref{sec:mult} we observed that the set
$T(\boldsymbol{\mu})$ was (effectively) semi-algebraic.  It follows
that we can express the condition $\forall \boldsymbol{z}\in
T(\boldsymbol{\mu}),\, f(\boldsymbol{z})^T\boldsymbol{u}\geq 0$ in the
first-order theory of the reals.  By the Tarski-Seidenberg theorem
\cite{Tar51} on quantifier elimination, the set of $\boldsymbol{u}\in
\mathbb{R}^d$ satisfying this condition is semi-algebraic.  But now
$\mathit{ENT}_i$ is the union of the two semi-algebraic sets
(\ref{eq:ENT1}) and (\ref{eq:ENT2}), and therefore $\mathit{ENT}_i$ is
itself semi-algebraic.
\end{proof}
\subsection{Definition of a Witness Set}
Having shown that $\mathit{ZERO}_i$ and $\mathit{ENT}_i$ are
semi-algebraic sets for $i=1,\ldots,m$, we now define a witness set
$W$ for the loop \textsf{P4}.

Given $\boldsymbol{u} \in \mathbb{R}^d$, write $\boldsymbol{u}=
\boldsymbol{u}_1+\ldots+\boldsymbol{u}_m$, with $\boldsymbol{u}_1 \in
V_1,\ldots,\boldsymbol{u}_m\in V_m$.  Say that $\boldsymbol{u}_i$ is
the \emph{dominant component} of $\boldsymbol{u}$ if
$\boldsymbol{u}_i\not\in \mathit{ZERO}_i$ and
$\boldsymbol{u}_j\in\mathit{ZERO}_j$ for all $j<i$.  The intuition is
that if $\boldsymbol{u}_i$ is dominant then the eventual
non-termination of \textsf{P4} on $\boldsymbol{u}$ is determined by
its eventual non-termination on $\boldsymbol{u}_i$.  However, to prove
this we need to assume $\boldsymbol{u}\in (\mathbb{A}\cap\mathbb{R})^d$.  Formally we
have:

\begin{proposition}
  If $\boldsymbol{u}_i$ is the dominant component of $\boldsymbol{u}
  \in (\mathbb{A}\cap\mathbb{R})^d$ then $\boldsymbol{u}\in\mathit{ENT}$ if and only
if $\boldsymbol{u}_i \in \mathit{ENT}$.
\label{prop:dominant}
\end{proposition}
\begin{proof}
From the fact that $\boldsymbol{u}_i$ is dominant we have:
\begin{eqnarray}
 \boldsymbol{b}^TA^n\boldsymbol{u}&=&
   \boldsymbol{b}^TA^n(\boldsymbol{u}_1+\cdots+\boldsymbol{u}_m) \notag\\
&=&\boldsymbol{b}^TA^n(\boldsymbol{u}_i+\cdots+\boldsymbol{u}_m)
\label{eq:part}
\end{eqnarray}
for all $n\geq d$.  Moreover, for each $j>i$ it is clear that
  $|\boldsymbol{b}^TA^n\boldsymbol{u}_j| = O(n^d\rho_j^n)$, where
  $\rho_j\geq 0$ is the modulus of the eigenvalues in $S_j$.

  We now consider three cases, mirroring the proof of
  \cref{prop:semi-alg}.

  The first case is that $A$ has dimension at most $5$.  As observed
  in the proof of \cref{prop:semi-alg}, all instances of
  this case that are not already covered by the second and third cases
  are such that $S_i$ contains all the eigenvalues of $A$, and hence
  $\boldsymbol{u}_i=\boldsymbol{u}$.  In this situation the proposition
  holds trivially.

  The second case is that $S_i$ does not contain a positive real
  eigenvalue.  Then it follows from~\cite[Lemma 4]{Bra06} that there
  is a constant $c<0$ such that
  $\boldsymbol{b}^TA^n\boldsymbol{u}_i<c\rho_i^n$ for infinitely many
  $n$.  In this case neither $\boldsymbol{u}_i$ nor $\boldsymbol{u}$
  are elements of $\mathit{ENT}$.

  It remains to consider the case that all complex eigenvalues in
  $S_i$ are simple.  Suppose that the dominant term in the expression
  for $\boldsymbol{b}^TA^n\boldsymbol{u}_i$ has the form $\alpha
  n^k\rho_i^n$ for some real constant $\alpha\neq 0$ and $k>0$.  If
  $\alpha>0$ then both $\boldsymbol{u}$ and $\boldsymbol{u}_i$ are in
  $\mathit{ENT}$ and if $\alpha<0$ then neither $\boldsymbol{u}$ or
  $\boldsymbol{u}_i$ are in $\mathit{ENT}$.

  Otherwise, specialising the expression (\ref{eq:master}) to the case
  at hand, we have that
\begin{gather}
\label{eq:diag}
 \boldsymbol{b}^TA^n\boldsymbol{u}_i = \alpha_0 \rho_i^n+\sum\limits_{j=1}^s\beta_j\lambda_j^n+\overline{\beta_j\lambda_j^n}
\end{gather}
where $\alpha_0$ and the $\beta_j$ are algebraic-integer constants and
$\rho_i,\lambda_1,\overline{\lambda_1},\ldots,\lambda_s,\overline{\lambda_s} \in S_i$.  In this case one can use the
$S$-units theorem of Evertse, van der Poorten, and
Schlickewei~\cite{Evertse84,PS82} to show that for all $\varepsilon>0$ it
is the case that $\boldsymbol{b}^TA^n\boldsymbol{u}_i =\Omega\left(
  \rho_i^n \Lambda^{-n\varepsilon} \right)$,
where $\Lambda$ is an upper bound on the absolute value of eigenvalues of $A$ (see the Appendix for details).

From this lower bound, taking $\varepsilon$ suitably small, it follows
that $|\boldsymbol{b}^TA^n\boldsymbol{u}_j|=o(|\boldsymbol{b}^TA^n
\boldsymbol{u}_i|)$ for all $j>i$ and hence that
$\boldsymbol{u}\in\mathit{ENT}$ if and only if $\boldsymbol{u}_i\in
\mathit{ENT}$.
\end{proof}

Now we define a witness set $W$ for program \textsf{P4} by
\begin{align*}
W :=   \bigcup_{i=1}^m \{\boldsymbol{u}\in \mathbb{R}^d: \,
         & \boldsymbol{u}_i \mbox{ is the dominant component of } \boldsymbol{u},\\
         & \boldsymbol{u}_i \in \mathit{ENT} \}
\cup \mathit{ZERO} \, .
\end{align*}

From the fact that $\mathit{ZERO}_i$, $\mathit{ENT}_i$, and $V_i$ are
semi-algebraic for $i=1,\ldots,m$, it is easy to see that $W$ is
semi-algebraic.  It moreover follows from \cref{prop:dominant}
that $W \cap \mathbb{A}^d = \mathit{ENT} \cap \mathbb{A}^d$.

To conclude the proof of \cref{prop:main2}, it
remains to observe that the witness set $W$, like the actual set
$\mathit{ENT}$ of eventually non-terminating points, is convex.
\begin{proposition}
The witness set $W$ is convex.
\end{proposition}
\begin{proof}
  Suppose $\boldsymbol y,\boldsymbol z\in W$ and let $\boldsymbol
  x=\lambda\boldsymbol y+(1-\lambda)\boldsymbol z$, where $0 < \lambda
  < 1$. Moreover, write
  $\boldsymbol{x}=\boldsymbol{x}_1+\ldots+\boldsymbol{x}_m$, where
  $\boldsymbol{x}_1\in V_1,\ldots,\boldsymbol{x}_m\in V_m$, and
  likewise for $\boldsymbol{y}$ and $\boldsymbol{z}$.

If $\boldsymbol{y},\boldsymbol{z}\in \mathit{ZERO}$ then
$\boldsymbol{x}\in \mathit{ZERO}$ since the latter is a convex set.

Suppose that $\boldsymbol{y}\in \mathit{ZERO}$ and $\boldsymbol{z}_i \in \mathit{ENT}$ is dominant for $\boldsymbol{z}$ for some index $i\in\{1,\ldots,m\}$.
Then $\boldsymbol{x}_i$ is dominant for $\boldsymbol{x}$, and
$\boldsymbol{x}_i \in \mathit{ENT}$.  Thus $\boldsymbol{x}\in W$.

Otherwise, let $\boldsymbol y_i$ be dominant for $\boldsymbol y$ and
$\boldsymbol z_j$ be dominant for $\boldsymbol z$ for some
$i,j\in\{1,\ldots,m\}$.  Then $\boldsymbol x_k\in \mathit{ZERO}_k$ for
all $k<\min\lbrace i,j\rbrace$ since $\mathit{ZERO}_k$ is convex.
Moreover if $k=\min\lbrace i,j\rbrace$ then $\boldsymbol
y_k,\boldsymbol z_k \in \mathit{ENT}_k$, and hence $\boldsymbol x_k
\in \mathit{ENT}_k$ by convexity of $\mathit{ENT}_k$.  It follows that
$\boldsymbol{x}\in W$.
\end{proof}

This concludes the proof of \cref{prop:main2}.
In the remaining part of this section we show that
$\overline{\mathit{ENT}}=\overline{W}$.

The inclusion $\overline{W}\subseteq \overline{ENT}$ can be shown
using the fact that the set algebraic points in any semi-algebraic set
is dense in that set. (See the Appendix for details).  From
this we have:
\begin{align*}
\overline{W}=\overline{W\cap\mathbb{A}^d}=\overline{\mathit{ENT}\cap\mathbb{A}^d} \subseteq \overline{\mathit{ENT}}\cap\overline{\mathbb{A}^d}=\overline{\mathit{ENT}}
\end{align*}

The reverse inclusion, $\overline{ENT}\subseteq\overline{W}$, can be
shown in similar fashion but this time using the fact that
$\mathit{ENT}\cap\mathbb{A}^d$ is dense in $\mathit{ENT}$.  Our
remaining goal is this last fact, which is established in
\cref{corl:dense} below.

We have previously shown that a vector of algebraic numbers
$\boldsymbol{u}\in (\mathbb{A}\cap\mathbb{R})^d$ is eventually
non-terminating if and only if its dominant component
$\boldsymbol{u}_i$ is eventually non-terminating.  We now prove a
partial result of this nature for general vectors $\boldsymbol{u}\in
\mathbb{R}^d$.

\begin{proposition}
  Suppose that $\boldsymbol u=\boldsymbol u_1+\cdots+\boldsymbol
  u_m\in \mathbb{R}^d$, where $\boldsymbol u_1\in
  V_1,\ldots,\boldsymbol u_m\in V_m$. Then $\boldsymbol
  u\in\mathit{ENT}$ implies that its dominant component $\boldsymbol
  u_i$ is also in \textit{ENT}.
\label{prop:dom2}
\end{proposition}
\begin{proof}
  The only non-trivial case corresponds to the situation in which
  $\boldsymbol b^T A^n \boldsymbol u_i$ is of the form (\ref{eq:diag}).
  Let $f$ and $\boldsymbol \mu$ be as in (\ref{eq:f-exp}), that is, so
  that $\boldsymbol b^T A^n \boldsymbol u_i=\rho_i^n f (\boldsymbol
  \mu^n)^T \boldsymbol u_i$. If $\boldsymbol u_i\not\in\mathit{ENT}$,
  then there exists some constant $c<0$ and some $\boldsymbol z\in T(\boldsymbol \mu)$ such that $f(\boldsymbol z)^T \boldsymbol u_i=c$. Therefore, for any $\varepsilon>0$, $\boldsymbol b^T A^n \boldsymbol u_i<(c+\varepsilon)\rho_i^n$ holds for infinitely many $n$, due to \cref{dense} and to continuity of $f$, and so $\boldsymbol u\not\in\mathit{ENT}$.
\end{proof}

\begin{corollary}
$\mathit{ENT}\cap\mathbb{A}^d$ is dense in \textit{ENT}.
\label{corl:dense}
\end{corollary}

\begin{proof}
  At several points we will rely on the fact that if
  $X\subseteq\mathbb{R}^d$ is semi-algebraic, then the algebraic
  points in $X$ are dense in $X$.  (See Appendix for details.)

  Fix $\boldsymbol u\in\mathit{ENT}$ and let $\varepsilon>0$ be
  given. We will find $\boldsymbol v\in \mathit{ENT}\cap \mathbb{A}^d$
  such that $||\boldsymbol u-\boldsymbol v||<\varepsilon$.

  The case in which $\boldsymbol u \in \mathit{ZERO}$ is easy since
  $\mathit{ZERO}$ is semi-algebraic and so we can take $\boldsymbol v$
  to be an algebraic point in $\mathit{ZERO}$ that is suitably close
  to $\boldsymbol u$.

  Suppose now that $\boldsymbol u=\boldsymbol u_1+\cdots+\boldsymbol
  u_m$, where $\boldsymbol u_1\in V_1,\ldots,\boldsymbol u_m\in V_m$,
  with $\boldsymbol u_i$ the dominant component of $\boldsymbol u$. By
  \cref{prop:dom2}, $\boldsymbol u\in\mathit{ENT}$ implies
  that $\boldsymbol u_i\in \mathit{ENT}$. Since $\mathit{ENT}\cap V_i$
  is semi-algebraic, we can pick $\boldsymbol v_i\in \mathit{ENT}\cap
  V_i\cap\mathbb{A}^d$ such that $\| \boldsymbol v_i -\boldsymbol u_i
  \|<\varepsilon/n$. For each $j>i$, we pick some $\boldsymbol v_j\in
  V_j\cap \mathbb{A}^d$ for which $\| \boldsymbol v_j - \boldsymbol
  u_j\|<\varepsilon/n$.  For each $j<i$ we pick some $v_j \in
  \mathit{ZERO}\cap V_j\cap \mathbb{A}^d$ for which $\| \boldsymbol
  v_j - \boldsymbol u_j\|<\varepsilon/n$.

  Then, letting $\boldsymbol v=\boldsymbol v_1+\cdots+\boldsymbol v_m
  \in \mathbb{A}^d$, it follows that $\|\boldsymbol u-\boldsymbol
  v\|<\varepsilon$.  Finally, by \cref{prop:dominant} we
  have $\boldsymbol v\in\mathit{ENT}$ since $\boldsymbol v_i$ is the
  dominant component of $\boldsymbol v$ and $\boldsymbol v_i \in
  \mathit{ENT}$ by construction.
\end{proof}
