\subsection{Laurent polynomials}

A multivariate \emph{Laurent polynomial} is a polynomial in positive and negative powers of variables $z_{1}, \ldots, z_{s}$ with complex coefficients. We are interested in Laurent polynomials of the special form
\[ g = \sum_{j=1}^k \left( c_j {z_1}^{n_{1,j}}\ldots {z_s}^{n_{s,j}} +
    \overline{c_j} {z_1}^{-n_{1,j}}\ldots {z_s}^{-n_{s,j}} \right) \,
\]
where $c_1,\ldots,c_k \in \mathbb{C}$ and $n_{1,1},\ldots,n_{s,k} \in \Integers$.  We call such $g$ \emph{self-conjugate Laurent polynomials}.  Notice that if $\myvector{a} \in \mathbb{T}^{s}$ then $g(\myvector{a})$ is a real number, so we may regard $g$ as a function from $\mathbb{T}^{s}$ to $\Reals$.

We say that $g$ is \emph{simple} if $g$ has no constant term and
each monomial in $g$ mentions only a single variable.

\begin{lemma}
\label{lem:first_bound}
Let $g \in \mathbb{C}[z^{\pm 1}_1,\ldots,z^{\pm 1}_s]$ be a self-conjugate Laurent polynomial that has no constant term.
Given $\myvector{\theta} \in \Reals^{s}$ such that $\cA(\myvector{\theta}) = \lbrace \myvector{0} \rbrace$, define a function $f: \Reals_{\geq 0} \rightarrow \Reals$ by
\[ f(t) = g(\exp(2 \pi i t \myvector{\theta})) \, .\]
Then either $f$ is identically zero, or
\begin{align*}
\liminf\limits_{n\rightarrow\infty} f(n) < 0 \, ,
\end{align*}
where $n$ ranges over the nonnegative integers.
\end{lemma}

\begin{proof}
Consider the function $h : \Reals^s \rightarrow \Reals$ given by $\myvector{x} \mapsto g(\exp(2 \pi i \myvector{x}))$.
We use an averaging argument to establish that either $h$ is identically zero on $\Reals^s$ or there exist $\myvector{x}^{\star} \in [0,1]$ such that $h(\myvector{x}^{\star}) < 0$.

Since, for all non-zero integers $n$,
\begin{equation*}
  \int_{0}^{1} \exp(2\pi i n x) dx = 0 \, ,
\end{equation*}
it holds that
\begin{equation*}
\int_{[0, 1]^{s}} h(\myvector{x}) d \myvector{x} = 0 \, .
\end{equation*}
%
Suppose that $h$ is not identically zero over $\Reals^s$ and hence not identically zero over $[0,1]^{s}$. Then $h$ cannot be nonnegative on $[0,1]^{s}$, since the integral over a set of positive measure of a continuous nonnegative function that is not identically zero must be strictly positive. We conclude that there must exist $\myvector{x}^{\star} \in [0,1]^{s}$ such that $h(\myvector{x}^{\star}) < 0$.

By assumption, $\cA(\myvector{\theta}) = \lbrace \myvector{0} \rbrace$. By \cref{corl:kronecker} it follows that
\[ \lbrace \exp(n \myvector{\theta}) : n \in \Naturals \} \]
is dense in $\mathbb{T}^s$ and hence has $ \exp(2 \pi i \myvector{x}^{\star})$ as a limit point. Since $h$ is continuous, there are arbitrarily large $n\in\Naturals$ for which
\[ f(n) = h(n \myvector{\theta}) \leq \frac{1}{2} h(\myvector{x}^{\star}) < 0 \, , \]
which proves the result.
\end{proof}

Note that this proof could be made constructive by using an effective version of Kronecker's Theorem, as studied in~\cite{ConstructiveKronecker1} and~\cite{ConstructiveKronecker2}, although we do not make use of this fact in the present thesis.

The following consequence of \cref{lem:first_bound} will be key to
proving decidability of the problem at hand. It is a continuous-time
analogue of~\cite[Lemma 4]{Bra06}.

\begin{theorem}
\label{thm:liminf}
Let $g\in\mathbb{C}[z_1^{\pm 1},\ldots,z_s^{\pm 1}]$ be a simple
self-conjugate Laurent polynomial and $\theta_{1}, \ldots, \theta_{s}$ be
non-zero real numbers. Then either
\begin{align*}
& g(\exp(2 \pi i t \theta_{1}),\ldots,\exp(2 \pi i t \theta_{s})) = 0 \mbox{ for all $t\in\Reals$}
\intertext{or}
&
\liminf\limits_{n\rightarrow\infty}  g(\exp(2 \pi i n \theta_{1}), \ldots, \exp(2 \pi i n \theta_{s})) < 0 \, ,
\end{align*}
where $n$ ranges over the nonnegative integers.
\end{theorem}

\begin{proof}
Note that if $1, \theta_{1}, \ldots, \theta_{s}$ are linear independent over $\Rationals$ then the result follows from \cref{lem:first_bound}.
Otherwise, let $\lbrace \theta_{i_{1}}, \ldots, \theta_{i_{k}} \rbrace$ be a maximal subset of $\lbrace \theta_{1}, \ldots, \theta_{s} \rbrace$ such that $1, \theta_{i_{1}}, \ldots, \theta_{i_{k}}$ are linearly independent over $\Rationals$.

Then, for some $N\in\Naturals$ and each $j$, one can write
\begin{equation*}
N\theta_{j}= \left( m  +\sum\limits_{l=1}^{k} n_{l}\theta_{i_{l}} \right) \, ,
\end{equation*}
where $m,n_{1},\ldots,n_{k}$ are integers that depend on $j$, whilst $N$ does not depend on $j$. It follows that for all $j$ and $t \in \Reals$,
\begin{align*}
\exp(2 \pi i N\theta_{j} t) &= \exp( 2 \pi i m t) \cdot \prod\limits_{l=1}^{k} \exp(2 \pi i  n_{l} \theta_{i_{l}} t) \\
&= \exp(2 \pi i t)^{m} \cdot \prod\limits_{l=1}^{k} \exp(2 \pi i \theta_{i_{l}} t)^{n_{l}}  \, .
\end{align*}
In other words, for all $j \geq k+1$, $\exp(2 \pi i N \theta_{j} t)$ can be written as a product of positive and negative powers of the terms
\begin{equation*}
  \exp(2 \pi i t), \exp(2 \pi i \theta_{i_{1}} t), \ldots, \exp(2 \pi i \theta_{i_{k}} t) \, .
\end{equation*}
It follows that there exists a self-conjugate Laurent polynomial
$h\in\Complex [z_1^{\pm 1},\ldots,z_k^{\pm 1}]$, not necessarily
simple, but with zero constant term, such that for all
$t\in \Reals$,
\[ g(\exp(2 \pi i N \theta_{1} t), \ldots, \exp(2 \pi i N \theta_{s} t)) =
  h(\exp(2 \pi i \theta_{i_{1}} t),\ldots,\exp(2 \pi i \theta_{i_{k}} t)) \, .\]
Since $1, \theta_{i_{1}}, \ldots, \theta_{i_{k}}$ are linearly independent over $\Rationals$, the result follows by applying \cref{lem:first_bound}
to $h$.
\end{proof}

In order to compare the asymptotic growth of expressions of the form
$t^{n}\exp(\lambda t)$, for $\lambda\in\Reals$ and
$n\in\Naturals_0$, we define $\prec$ to be the lexicographic order on
$\Reals\times\Naturals_{0}$, that is,
\begin{equation*}
(\eta,j)\prec (\rho,m) \quad \mbox{iff} \quad
\eta<\rho \mbox{ or } (\eta = \rho \mbox{ and } j< m) \, .
\end{equation*}
Clearly $\exp(\eta t)t^{j}=o(\exp(\rho t)t^{m})$ as $t\rightarrow \infty$ if and only if $(\eta,j)\prec (\rho,m)$.

\begin{definition}
If $\boldsymbol{b}^{T}\exp(At)\boldsymbol{v}$ is not identically zero,
the maximal $(\rho,m)\in\Reals\times\Naturals_{0}$ with respect
to $\prec$ for which there is a term $t^{m}\exp (\lambda t)$ with
$\Re(\lambda)=\rho$ in the closed-form expression for
$\boldsymbol{b}^{T}\exp(At)\boldsymbol{v}$ is called \emph{dominant} for
$\boldsymbol{b}^{T}\exp(At)\boldsymbol{v}$.
\end{definition}

We now derive a useful corollary of \cref{thm:liminf}:

\begin{corollary}
\label{cor:liminf}
Consider a function of the form $h(t)=\boldsymbol{b}^{T}\exp(At) \boldsymbol{v}^{c}$, where $\boldsymbol{v}^{c}\in\mathcal{V}^{c}$, with $(\rho,m)\in\Reals\times \Naturals_{0}$ dominant. If $h(t)\not\equiv 0$, then we have
\begin{equation*}
-\infty<\liminf\limits_{t\rightarrow\infty} \frac{h(t)}{\exp(\rho
  t)t^{m}}<0 \, .
\end{equation*}
\end{corollary}

\begin{proof}
  Let
  $\Re(\sigma(A))=\lbrace \eta\in\Reals:
  \eta+i\theta\in\sigma(A),\mbox{ for some }\theta\in\Reals
  \rbrace$. Moreover, for $\eta\in\Re(\sigma(A))$, we define
  $\boldsymbol{\theta}_{\eta}=\lbrace \theta\in\Reals_{>0}:
  \eta+i\theta \in\sigma(A) \rbrace$. By abuse of notation, we also
  use $\boldsymbol{\theta}_{\eta}$ to refer to the vector whose
  coordinates are exactly the members of this set, ordered in an
  increasing way. We note that, due to \cref{conj-relation}
  and \cref{prop:linear}, the
  following holds:

\begin{align*}
\boldsymbol{b}^{T}\exp(At)\boldsymbol{v}^{c} &= \boldsymbol{b}^{T} \exp(At) \sum\limits_{\eta\in\Re(\sigma(A))} \sum\limits_{\theta\in\boldsymbol{\theta}_{\eta}} \boldsymbol{v}_{\eta+i\theta}+\boldsymbol{v}_{\eta-i\theta} \\
&= \sum\limits_{\eta\in\Re(\sigma(A))} \sum\limits_{\theta\in\boldsymbol{\theta}_{\eta}} \boldsymbol{b}^{T} \exp(At) \boldsymbol{v}_{\eta+i\theta} \\
& \qquad \qquad \qquad \qquad \qquad + \overline{\boldsymbol{b}^{T} \exp(At) \boldsymbol{v}_{\eta+i\theta}} \\
& = \sum\limits_{\eta\in\Re(\sigma(A))} \sum\limits_{j=0}^{\nu(A)-1} t^{j}\exp(\eta t)  g_{(\eta,j)}( \exp(i\boldsymbol{\theta}_{\eta}t) )
\end{align*}
for some simple self-conjugate Laurent polynomials
$g_{(\eta,j)}$.
Note that
\begin{equation*}
(\rho,m)=\max\limits_{\prec} \lbrace (\eta,j)\in\Reals\times
\Naturals_{0}: g_{(\eta,j)}(\exp(i\boldsymbol{\theta}_{\eta} t)) \not
\equiv 0 \rbrace \, .
\end{equation*}

The result then follows from \cref{thm:liminf} and the fact
that
\begin{align*}
\liminf\limits_{t\rightarrow\infty} \frac{h(t)}{\exp(\rho t)t^{m}}=
  \liminf\limits_{t\rightarrow\infty}
  g_{(\rho,m)}(\exp(i\boldsymbol{\theta}_{\rho} t)) \, .
\end{align*}
\end{proof}
